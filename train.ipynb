{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pyspark.sql import SparkSession\n",
    "from enum import Enum\n",
    "\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as sf\n",
    "\n",
    "from tqdm import tqdm\n",
    "class ResidueType(Enum):\n",
    "    ADEINE = 1\n",
    "    CYTHOSINE = 2\n",
    "    URACIL = 3\n",
    "    GUANINE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/17 18:55:47 WARN Utils: Your hostname, workstation resolves to a loopback address: 127.0.1.1; using 192.168.0.17 instead (on interface enp11s0)\n",
      "24/03/17 18:55:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/17 18:55:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1033"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"ribonanza\")\\\n",
    "        .config(\"spark.driver.memory\", \"10g\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "train_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/home/adamczykb/projects/ribonanza/data/csv/train_data_QUICK_START.csv\")\n",
    "    \n",
    "# train_df = train_df[train_df[\"SN_filter\"].values > 0]\n",
    "train_df = train_df.drop(*[c for c in train_df.columns if \"_error_\" in c])\n",
    "\n",
    "df_2A3 = train_df.filter(train_df.experiment_type == \"2A3_MaP\")\n",
    "df_DMS = train_df.filter(train_df.experiment_type == \"DMS_MaP\")\n",
    "\n",
    "pk50_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/home/adamczykb/projects/ribonanza/data/csv/PK50_silico_predictions.csv\") \\\n",
    "    .withColumnRenamed('hotknots_mfe', 'hotknots') \\\n",
    "    [\"sequence\",\"hotknots\"]\n",
    "pk90_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/home/adamczykb/projects/ribonanza/data/csv/PK90_silico_predictions.csv\") \\\n",
    "    .withColumnRenamed('hotknots_mfe', 'hotknots') \\\n",
    "    [\"sequence\",\"hotknots\"]\n",
    "r1_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/home/adamczykb/projects/ribonanza/data/csv/R1_silico_predictions.csv\") \\\n",
    "    [\"sequence\",\"hotknots\"]\n",
    "gpn15k_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/home/adamczykb/projects/ribonanza/data/csv/GPN15k_silico_predictions.csv\") \\\n",
    "    [\"sequence\",\"hotknots\"]\n",
    "\n",
    "pairing = pk50_df.union(pk90_df).union(r1_df).union(gpn15k_df)\n",
    "\n",
    "\n",
    "df_2A3 = df_2A3.join(pairing, on='sequence')\n",
    "df_DMS = df_DMS.join(pairing, on='sequence')\n",
    "\n",
    "del pk50_df,pk90_df,r1_df,gpn15k_df,pairing,train_df\n",
    "gc.collect()\n",
    "    # return df_2A3, df_DMS\n",
    "    # _2a3_csv_path = process_structure(df_2A3)\n",
    "    # dms_csv_path = process_structure(df_DMS)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2A3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import arrays_zip, col, explode,concat_ws,split\n",
    "cols=[\"reactivity_00{:02d}\".format(i) for i in range(1,27)]\n",
    "test = df_2A3.withColumn(\"sequence\", sf.expr(\"substr(sequence, 26, 999)\"))\\\n",
    "    .drop(*cols)\n",
    "df=test\\\n",
    "    .withColumn(\"reactivity\", sf.concat_ws(\",\", *[sf.col(x) for x in test.columns if \"reactivity_\" in x]))\\\n",
    "    .withColumn(\"reactivity\", sf.split(sf.col(\"reactivity\"),\",\"))\\\n",
    "    .withColumn(\"sequence\", sf.split(sf.col(\"sequence\"),\"\"))\\\n",
    "    .withColumn(\"hotknots\", sf.split(sf.col(\"hotknots\"),\"\"))\\\n",
    "    .withColumn(\"triplet\", sf.arrays_zip(\"sequence\", \"reactivity\",\"hotknots\")) \\\n",
    "    .withColumn(\"triplet\", sf.explode(\"triplet\")) \\\n",
    "    .select(\"sequence_id\",  sf.col(\"triplet\").sequence.alias('nucleotide'),sf.col(\"triplet\").reactivity.cast(\"float\").alias('reactivity'),sf.col(\"triplet\").hotknots.alias('pairing'))\\\n",
    "    .withColumn(\"reactivity\", sf.when(sf.col(\"reactivity\") < 0, 0).otherwise(col(\"reactivity\"))) \\\n",
    "    .replace({'.': '0','(':'1',')':'1','{':'2','}':'2','[':'3',']':'3','<':'4','>':'4','A':'5','a':'5','B':'6','b':'6'},subset=['pairing'])\\\n",
    "    .replace({'A':str(ResidueType.ADEINE.value),'C':str(ResidueType.CYTHOSINE.value),'G':str(ResidueType.GUANINE.value),'U':str(ResidueType.URACIL.value)},subset=['nucleotide'])\\\n",
    "    .withColumn(\"nucleotide\", col(\"nucleotide\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/17 18:55:52 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 14:=====================================================>  (24 + 1) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+------+\n",
      "| sequence_id|              tokens|          reactivity|length|\n",
      "+------------+--------------------+--------------------+------+\n",
      "|00c09b2f5db5|[{1, 0}, {3, 0}, ...|[1.364, 0.346, 0....|   115|\n",
      "|2577ae738ad5|[{1, 0}, {3, 0}, ...|[0.109, 0.011, 0....|   115|\n",
      "|2b498d53e42e|[{1, 1}, {4, 1}, ...|[0.044, 0.014, 0....|   115|\n",
      "|65235960e5d3|[{1, 0}, {3, 0}, ...|[1.837, 0.405, 0....|   115|\n",
      "|0e32f3defde4|[{1, 1}, {4, 1}, ...|[0.186, 1.13, 0.1...|   115|\n",
      "|29fe5407b168|[{1, 1}, {1, 1}, ...|[0.062, 0.193, 0....|   115|\n",
      "|5dd225e9bdb7|[{1, 1}, {1, 1}, ...|[0.103, 0.954, 0....|   115|\n",
      "|23905c52de44|[{1, 0}, {1, 0}, ...|[0.031, 1.479, 0....|   115|\n",
      "|2e4891e0dd14|[{1, 0}, {3, 0}, ...|[0.304, 0.041, 0....|   115|\n",
      "|2a6e753b286b|[{1, 0}, {3, 0}, ...|[1.599, 0.27, 0.4...|   115|\n",
      "|2c58166daa45|[{1, 0}, {3, 1}, ...|[0.527, 0.012, 0....|   115|\n",
      "|052c39e93e98|[{1, 0}, {3, 0}, ...|[0.151, 0.017, 0....|   115|\n",
      "|2c67c8f4d724|[{1, 1}, {3, 1}, ...|[1.409, 0.146, 0....|   115|\n",
      "|2fcba3eca9bf|[{1, 0}, {4, 0}, ...|[0.249, 0.754, 0....|   115|\n",
      "|2919907dbddc|[{1, 1}, {4, 1}, ...|[1.266, 0.007, 0....|   115|\n",
      "|071c8b055301|[{1, 0}, {4, 0}, ...|[0.348, 0.488, 0....|   115|\n",
      "|279ad8f106bc|[{1, 0}, {1, 0}, ...|[0.061, 0.87, 0.1...|   115|\n",
      "|3067029abe58|[{1, 1}, {4, 1}, ...|[0.813, 0.453, 0....|   115|\n",
      "|2d8818701b7e|[{1, 1}, {1, 1}, ...|[0.188, 1.176, 0....|   115|\n",
      "|01afb0c3c33e|[{1, 1}, {4, 1}, ...|[0.662, 0.464, 0....|   115|\n",
      "+------------+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/17 18:56:02 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "df2 = (\n",
    "        df.select(\"sequence_id\", \"nucleotide\", \"pairing\", \"reactivity\")\n",
    "        .groupby(\"sequence_id\")\n",
    "        .agg(\n",
    "            sf.collect_list(sf.struct(\"nucleotide\", \"pairing\")).alias(\"tokens\"),\n",
    "            sf.collect_list(\"reactivity\").alias(\"reactivity\"),\n",
    "        )\n",
    "        .withColumn(\"length\",sf.size(\"tokens\"))\n",
    "        .select(\"sequence_id\", \"tokens\", \"reactivity\",\"length\")\n",
    "        .sort(sf.asc(\"length\"))\n",
    "    )\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "file = h5py.File(\"/home/adamczykb/projects/ribonanza/data/parsed_dms.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tables\n",
      "  Downloading tables-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/lib/python3.11/site-packages (from tables) (1.26.4)\n",
      "Collecting numexpr>=2.6.2 (from tables)\n",
      "  Downloading numexpr-2.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.11/site-packages (from tables) (23.2)\n",
      "Collecting py-cpuinfo (from tables)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting blosc2>=2.3.0 (from tables)\n",
      "  Downloading blosc2-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting ndindex>=1.4 (from blosc2>=2.3.0->tables)\n",
      "  Using cached ndindex-1.8-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: msgpack in /usr/lib/python3.11/site-packages (from blosc2>=2.3.0->tables) (1.0.5)\n",
      "Downloading tables-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading blosc2-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numexpr-2.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (377 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.5/377.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached ndindex-1.8-py3-none-any.whl (91 kB)\n",
      "Installing collected packages: py-cpuinfo, numexpr, ndindex, blosc2, tables\n",
      "Successfully installed blosc2-2.5.1 ndindex-1.8 numexpr-2.9.0 py-cpuinfo-9.0.0 tables-3.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tables --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# a=pd.read_hdf(\"/home/adamczykb/projects/ribonanza/data/parsed_dms.h5\",\"sequence_id\")\n",
    "\n",
    "import tables\n",
    "a=tables.open_file(\"/home/adamczykb/projects/ribonanza/data/parsed_dms.h5\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting h5torch\n",
      "  Downloading h5torch-0.2.14-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3.11/site-packages (from h5torch) (1.26.4)\n",
      "Requirement already satisfied: h5py in /home/adamczykb/.local/lib/python3.11/site-packages (from h5torch) (3.10.0)\n",
      "Requirement already satisfied: torch in /home/adamczykb/.local/lib/python3.11/site-packages (from h5torch) (2.0.1)\n",
      "Requirement already satisfied: scipy in /home/adamczykb/.local/lib/python3.11/site-packages (from h5torch) (1.11.2)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.11/site-packages (from torch->h5torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/lib/python3.11/site-packages (from torch->h5torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.11/site-packages (from torch->h5torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/adamczykb/.local/lib/python3.11/site-packages (from torch->h5torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/adamczykb/.local/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->h5torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->h5torch) (0.42.0)\n",
      "Requirement already satisfied: cmake in /home/adamczykb/.local/lib/python3.11/site-packages (from triton==2.0.0->torch->h5torch) (3.27.0)\n",
      "Requirement already satisfied: lit in /usr/lib/python3.11/site-packages (from triton==2.0.0->torch->h5torch) (16.0.6.dev0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3.11/site-packages (from jinja2->torch->h5torch) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/adamczykb/.local/lib/python3.11/site-packages (from sympy->torch->h5torch) (1.3.0)\n",
      "Downloading h5torch-0.2.14-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: h5torch\n",
      "Successfully installed h5torch-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip3 install h5torch --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a=pd.read_hdf(\"/home/adamczykb/projects/ribonanza/data/parsed_dms.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2840000092983246,\n",
       " 0.15199999511241913,\n",
       " 0.035999998450279236,\n",
       " 0.0020000000949949026,\n",
       " 0.026000000536441803,\n",
       " 0.31700000166893005,\n",
       " 0.32100000977516174,\n",
       " 0.9559999704360962,\n",
       " 2.9110000133514404,\n",
       " 0.7630000114440918,\n",
       " 0.7210000157356262,\n",
       " 0.013000000268220901,\n",
       " 0.2809999883174896,\n",
       " 0.14900000393390656,\n",
       " 0.019999999552965164,\n",
       " 0.0689999982714653,\n",
       " 0.027000000700354576,\n",
       " 0.07800000160932541,\n",
       " 0.07800000160932541,\n",
       " 0.0560000017285347,\n",
       " 0.26499998569488525,\n",
       " 0.02199999988079071,\n",
       " 0.2029999941587448,\n",
       " 0.10599999874830246,\n",
       " 0.6600000262260437,\n",
       " 0.14000000059604645,\n",
       " 1.4259999990463257,\n",
       " 1.4420000314712524,\n",
       " 0.032999999821186066,\n",
       " 0.019999999552965164,\n",
       " 0.17299999296665192,\n",
       " 0.05299999937415123,\n",
       " 0.10700000077486038,\n",
       " 1.5880000591278076,\n",
       " 0.0949999988079071,\n",
       " 0.13699999451637268,\n",
       " 0.3240000009536743,\n",
       " 0.12099999934434891,\n",
       " 0.03500000014901161,\n",
       " 0.03799999877810478,\n",
       " 0.13899999856948853,\n",
       " 0.9860000014305115,\n",
       " 0.3889999985694885,\n",
       " 0.39800000190734863,\n",
       " 0.05999999865889549,\n",
       " 0.8410000205039978,\n",
       " 0.0430000014603138,\n",
       " 0.17900000512599945,\n",
       " 0.041999999433755875,\n",
       " 0.11599999666213989,\n",
       " 0.06199999898672104,\n",
       " 0.6420000195503235,\n",
       " 0.05999999865889549,\n",
       " 0.125,\n",
       " 0.05400000140070915,\n",
       " 0.039000000804662704,\n",
       " 0.07400000095367432,\n",
       " 0.004999999888241291,\n",
       " 0.19499999284744263,\n",
       " 1.3209999799728394,\n",
       " 0.12200000137090683,\n",
       " 0.023000000044703484,\n",
       " 0.26499998569488525,\n",
       " 0.14000000059604645,\n",
       " 0.03400000184774399,\n",
       " 0.01600000075995922,\n",
       " 0.03200000151991844,\n",
       " 0.20600000023841858,\n",
       " 0.3269999921321869]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['reactivity'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `reactivity` cannot be resolved. Did you mean one of the following? [`reactivity_0001`, `reactivity_0002`, `reactivity_0003`, `reactivity_0004`, `reactivity_0005`].;\n'Project ['reactivity]\n+- Project [sequence#1948, sequence_id#1947, experiment_type#1949, dataset_name#1950, reactivity_0001#1951, reactivity_0002#1952, reactivity_0003#1953, reactivity_0004#1954, reactivity_0005#1955, reactivity_0006#1956, reactivity_0007#1957, reactivity_0008#1958, reactivity_0009#1959, reactivity_0010#1960, reactivity_0011#1961, reactivity_0012#1962, reactivity_0013#1963, reactivity_0014#1964, reactivity_0015#1965, reactivity_0016#1966, reactivity_0017#1967, reactivity_0018#1968, reactivity_0019#1969, reactivity_0020#1970, ... 187 more fields]\n   +- Join Inner, (sequence#1948 = sequence#3008)\n      :- Filter (experiment_type#1949 = 2A3_MaP)\n      :  +- Project [sequence_id#1947, sequence#1948, experiment_type#1949, dataset_name#1950, reactivity_0001#1951, reactivity_0002#1952, reactivity_0003#1953, reactivity_0004#1954, reactivity_0005#1955, reactivity_0006#1956, reactivity_0007#1957, reactivity_0008#1958, reactivity_0009#1959, reactivity_0010#1960, reactivity_0011#1961, reactivity_0012#1962, reactivity_0013#1963, reactivity_0014#1964, reactivity_0015#1965, reactivity_0016#1966, reactivity_0017#1967, reactivity_0018#1968, reactivity_0019#1969, reactivity_0020#1970, ... 186 more fields]\n      :     +- Relation [sequence_id#1947,sequence#1948,experiment_type#1949,dataset_name#1950,reactivity_0001#1951,reactivity_0002#1952,reactivity_0003#1953,reactivity_0004#1954,reactivity_0005#1955,reactivity_0006#1956,reactivity_0007#1957,reactivity_0008#1958,reactivity_0009#1959,reactivity_0010#1960,reactivity_0011#1961,reactivity_0012#1962,reactivity_0013#1963,reactivity_0014#1964,reactivity_0015#1965,reactivity_0016#1966,reactivity_0017#1967,reactivity_0018#1968,reactivity_0019#1969,reactivity_0020#1970,... 392 more fields] csv\n      +- Union false, false\n         :- Project [sequence#3008, hotknots#3069]\n         :  +- Project [id#3007, sequence#3008, notes#3009, eterna_nupack#3010, eterna_eternafold+threshknot#3011, vienna2_mfe#3012, contrafold2_mfe#3013, eternafold_mfe#3014, e2efold_mfe#3015, hotknots_mfe#3016 AS hotknots#3069, ipknots_mfe#3017, knotty_mfe#3018, pknots_mfe#3019, spotrna_mfe#3020, vienna[threshknot]_mfe#3021, vienna[hungarian]_mfe#3022, eternafold[threshknot]_mfe#3023, eternafold[hungarian]_mfe#3024, contrafold[threshknot]_mfe#3025, contrafold[hungarian]_mfe#3026, nupack[threshknot]_mfe#3027, nupack[hungarian]_mfe#3028, shapify_mfe#3029, eternafold+hfold_1#3030, ... 7 more fields]\n         :     +- Relation [id#3007,sequence#3008,notes#3009,eterna_nupack#3010,eterna_eternafold+threshknot#3011,vienna2_mfe#3012,contrafold2_mfe#3013,eternafold_mfe#3014,e2efold_mfe#3015,hotknots_mfe#3016,ipknots_mfe#3017,knotty_mfe#3018,pknots_mfe#3019,spotrna_mfe#3020,vienna[threshknot]_mfe#3021,vienna[hungarian]_mfe#3022,eternafold[threshknot]_mfe#3023,eternafold[hungarian]_mfe#3024,contrafold[threshknot]_mfe#3025,contrafold[hungarian]_mfe#3026,nupack[threshknot]_mfe#3027,nupack[hungarian]_mfe#3028,shapify_mfe#3029,eternafold+hfold_1#3030,... 7 more fields] csv\n         :- Project [sequence#3125, hotknots#3191]\n         :  +- Project [id#3121, title#3122, name#3123, body#3124, sequence#3125, eterna_nupack#3126, eterna_eternafold+threshknot#3127, vienna2_mfe#3128, contrafold2_mfe#3129, eternafold_mfe#3130, e2efold_mfe#3131, hotknots_mfe#3132 AS hotknots#3191, ipknots_mfe#3133, knotty_mfe#3134, pknots_mfe#3135, spotrna_mfe#3136, vienna[threshknot]_mfe#3137, vienna[hungarian]_mfe#3138, eternafold[threshknot]_mfe#3139, eternafold[hungarian]_mfe#3140, contrafold[threshknot]_mfe#3141, contrafold[hungarian]_mfe#3142, nupack[threshknot]_mfe#3143, nupack[hungarian]_mfe#3144, ... 11 more fields]\n         :     +- Relation [id#3121,title#3122,name#3123,body#3124,sequence#3125,eterna_nupack#3126,eterna_eternafold+threshknot#3127,vienna2_mfe#3128,contrafold2_mfe#3129,eternafold_mfe#3130,e2efold_mfe#3131,hotknots_mfe#3132,ipknots_mfe#3133,knotty_mfe#3134,pknots_mfe#3135,spotrna_mfe#3136,vienna[threshknot]_mfe#3137,vienna[hungarian]_mfe#3138,eternafold[threshknot]_mfe#3139,eternafold[hungarian]_mfe#3140,contrafold[threshknot]_mfe#3141,contrafold[hungarian]_mfe#3142,nupack[threshknot]_mfe#3143,nupack[hungarian]_mfe#3144,... 11 more fields] csv\n         :- Project [sequence#3251, hotknots#3259]\n         :  +- Relation [rowID#3247,id#3248,name#3249,body#3250,sequence#3251,title#3252,vienna2_mfe#3253,vienna2_time#3254,contrafold2_mfe#3255,contrafold2_time#3256,eternafold_mfe#3257,eternafold_time#3258,hotknots#3259,hotknots_time#3260,ipknots#3261,ipknots_time#3262,knotty#3263,knotty_time#3264,spotrna#3265,spotrna_time#3266,nupack_pk#3267,nupack_pk_time#3268,vienna_2[threshknot]#3269,vienna_2[threshknot]_time#3270,... 20 more fields] csv\n         +- Project [sequence#3357, hotknots#3364]\n            +- Relation [rowID#3355,seqID#3356,sequence#3357,vienna2_mfe#3358,vienna2_time#3359,contrafold2_mfe#3360,contrafold2_time#3361,eternafold_mfe#3362,eternafold_time#3363,hotknots#3364,hotknots_time#3365,ipknots#3366,ipknots_time#3367,knotty#3368,knotty_time#3369,spotrna#3370,spotrna_time#3371,nupack_pk#3372,nupack_pk_time#3373,vienna_2[threshknot]#3374,vienna_2[threshknot]_time#3375,vienna_2[hungarian]#3376,vienna_2[hungarian]_time#3377,eternafold[threshknot]#3378,... 13 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[43mdf_2A3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapproxQuantile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreactivity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      2\u001b[0m upper_limit \u001b[38;5;241m=\u001b[39m q[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.5\u001b[39m\u001b[38;5;241m*\u001b[39m(q[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m-\u001b[39mq[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:4845\u001b[0m, in \u001b[0;36mDataFrame.approxQuantile\u001b[0;34m(self, col, probabilities, relativeError)\u001b[0m\n\u001b[1;32m   4836\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[1;32m   4837\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEGATIVE_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4838\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4841\u001b[0m         },\n\u001b[1;32m   4842\u001b[0m     )\n\u001b[1;32m   4843\u001b[0m relativeError \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(relativeError)\n\u001b[0;32m-> 4845\u001b[0m jaq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapproxQuantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelativeError\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4846\u001b[0m jaq_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(j) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m jaq]\n\u001b[1;32m   4847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jaq_list[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m isStr \u001b[38;5;28;01melse\u001b[39;00m jaq_list\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `reactivity` cannot be resolved. Did you mean one of the following? [`reactivity_0001`, `reactivity_0002`, `reactivity_0003`, `reactivity_0004`, `reactivity_0005`].;\n'Project ['reactivity]\n+- Project [sequence#1948, sequence_id#1947, experiment_type#1949, dataset_name#1950, reactivity_0001#1951, reactivity_0002#1952, reactivity_0003#1953, reactivity_0004#1954, reactivity_0005#1955, reactivity_0006#1956, reactivity_0007#1957, reactivity_0008#1958, reactivity_0009#1959, reactivity_0010#1960, reactivity_0011#1961, reactivity_0012#1962, reactivity_0013#1963, reactivity_0014#1964, reactivity_0015#1965, reactivity_0016#1966, reactivity_0017#1967, reactivity_0018#1968, reactivity_0019#1969, reactivity_0020#1970, ... 187 more fields]\n   +- Join Inner, (sequence#1948 = sequence#3008)\n      :- Filter (experiment_type#1949 = 2A3_MaP)\n      :  +- Project [sequence_id#1947, sequence#1948, experiment_type#1949, dataset_name#1950, reactivity_0001#1951, reactivity_0002#1952, reactivity_0003#1953, reactivity_0004#1954, reactivity_0005#1955, reactivity_0006#1956, reactivity_0007#1957, reactivity_0008#1958, reactivity_0009#1959, reactivity_0010#1960, reactivity_0011#1961, reactivity_0012#1962, reactivity_0013#1963, reactivity_0014#1964, reactivity_0015#1965, reactivity_0016#1966, reactivity_0017#1967, reactivity_0018#1968, reactivity_0019#1969, reactivity_0020#1970, ... 186 more fields]\n      :     +- Relation [sequence_id#1947,sequence#1948,experiment_type#1949,dataset_name#1950,reactivity_0001#1951,reactivity_0002#1952,reactivity_0003#1953,reactivity_0004#1954,reactivity_0005#1955,reactivity_0006#1956,reactivity_0007#1957,reactivity_0008#1958,reactivity_0009#1959,reactivity_0010#1960,reactivity_0011#1961,reactivity_0012#1962,reactivity_0013#1963,reactivity_0014#1964,reactivity_0015#1965,reactivity_0016#1966,reactivity_0017#1967,reactivity_0018#1968,reactivity_0019#1969,reactivity_0020#1970,... 392 more fields] csv\n      +- Union false, false\n         :- Project [sequence#3008, hotknots#3069]\n         :  +- Project [id#3007, sequence#3008, notes#3009, eterna_nupack#3010, eterna_eternafold+threshknot#3011, vienna2_mfe#3012, contrafold2_mfe#3013, eternafold_mfe#3014, e2efold_mfe#3015, hotknots_mfe#3016 AS hotknots#3069, ipknots_mfe#3017, knotty_mfe#3018, pknots_mfe#3019, spotrna_mfe#3020, vienna[threshknot]_mfe#3021, vienna[hungarian]_mfe#3022, eternafold[threshknot]_mfe#3023, eternafold[hungarian]_mfe#3024, contrafold[threshknot]_mfe#3025, contrafold[hungarian]_mfe#3026, nupack[threshknot]_mfe#3027, nupack[hungarian]_mfe#3028, shapify_mfe#3029, eternafold+hfold_1#3030, ... 7 more fields]\n         :     +- Relation [id#3007,sequence#3008,notes#3009,eterna_nupack#3010,eterna_eternafold+threshknot#3011,vienna2_mfe#3012,contrafold2_mfe#3013,eternafold_mfe#3014,e2efold_mfe#3015,hotknots_mfe#3016,ipknots_mfe#3017,knotty_mfe#3018,pknots_mfe#3019,spotrna_mfe#3020,vienna[threshknot]_mfe#3021,vienna[hungarian]_mfe#3022,eternafold[threshknot]_mfe#3023,eternafold[hungarian]_mfe#3024,contrafold[threshknot]_mfe#3025,contrafold[hungarian]_mfe#3026,nupack[threshknot]_mfe#3027,nupack[hungarian]_mfe#3028,shapify_mfe#3029,eternafold+hfold_1#3030,... 7 more fields] csv\n         :- Project [sequence#3125, hotknots#3191]\n         :  +- Project [id#3121, title#3122, name#3123, body#3124, sequence#3125, eterna_nupack#3126, eterna_eternafold+threshknot#3127, vienna2_mfe#3128, contrafold2_mfe#3129, eternafold_mfe#3130, e2efold_mfe#3131, hotknots_mfe#3132 AS hotknots#3191, ipknots_mfe#3133, knotty_mfe#3134, pknots_mfe#3135, spotrna_mfe#3136, vienna[threshknot]_mfe#3137, vienna[hungarian]_mfe#3138, eternafold[threshknot]_mfe#3139, eternafold[hungarian]_mfe#3140, contrafold[threshknot]_mfe#3141, contrafold[hungarian]_mfe#3142, nupack[threshknot]_mfe#3143, nupack[hungarian]_mfe#3144, ... 11 more fields]\n         :     +- Relation [id#3121,title#3122,name#3123,body#3124,sequence#3125,eterna_nupack#3126,eterna_eternafold+threshknot#3127,vienna2_mfe#3128,contrafold2_mfe#3129,eternafold_mfe#3130,e2efold_mfe#3131,hotknots_mfe#3132,ipknots_mfe#3133,knotty_mfe#3134,pknots_mfe#3135,spotrna_mfe#3136,vienna[threshknot]_mfe#3137,vienna[hungarian]_mfe#3138,eternafold[threshknot]_mfe#3139,eternafold[hungarian]_mfe#3140,contrafold[threshknot]_mfe#3141,contrafold[hungarian]_mfe#3142,nupack[threshknot]_mfe#3143,nupack[hungarian]_mfe#3144,... 11 more fields] csv\n         :- Project [sequence#3251, hotknots#3259]\n         :  +- Relation [rowID#3247,id#3248,name#3249,body#3250,sequence#3251,title#3252,vienna2_mfe#3253,vienna2_time#3254,contrafold2_mfe#3255,contrafold2_time#3256,eternafold_mfe#3257,eternafold_time#3258,hotknots#3259,hotknots_time#3260,ipknots#3261,ipknots_time#3262,knotty#3263,knotty_time#3264,spotrna#3265,spotrna_time#3266,nupack_pk#3267,nupack_pk_time#3268,vienna_2[threshknot]#3269,vienna_2[threshknot]_time#3270,... 20 more fields] csv\n         +- Project [sequence#3357, hotknots#3364]\n            +- Relation [rowID#3355,seqID#3356,sequence#3357,vienna2_mfe#3358,vienna2_time#3359,contrafold2_mfe#3360,contrafold2_time#3361,eternafold_mfe#3362,eternafold_time#3363,hotknots#3364,hotknots_time#3365,ipknots#3366,ipknots_time#3367,knotty#3368,knotty_time#3369,spotrna#3370,spotrna_time#3371,nupack_pk#3372,nupack_pk_time#3373,vienna_2[threshknot]#3374,vienna_2[threshknot]_time#3375,vienna_2[hungarian]#3376,vienna_2[hungarian]_time#3377,eternafold[threshknot]#3378,... 13 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "q = df_2A3.approxQuantile('reactivity', [0.25, 0.5, 0.75], 0) \n",
    "upper_limit = q[2] + 1.5*(q[2]-q[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4265000484883785"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "aaa=df2.select(sf.col(\"tokens\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a=df2.select(sf.col(\"tokens\")).rdd.map(tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'PipelinedRDD' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzipWithIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PipelinedRDD' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a.zipWithIndex().filter(lambda x: x[1] == 1).map(lambda x: x[0]).collect()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
